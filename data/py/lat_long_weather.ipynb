{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-13T03:16:22.402057Z",
     "start_time": "2020-08-13T03:16:22.022320Z"
    }
   },
   "outputs": [],
   "source": [
    "# Dependencies and Setup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from pprint import pprint\n",
    "import requests\n",
    "from datetime import date, timedelta, datetime\n",
    "import json\n",
    "# Import API key\n",
    "from config import weather_api_key\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-11T23:36:29.183999Z",
     "start_time": "2020-08-11T23:36:29.180008Z"
    },
    "heading_collapsed": true
   },
   "source": [
    "### Get Long Lat list of tuples to pass into Weather API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-12T21:55:25.972960Z",
     "start_time": "2020-08-12T21:55:25.970943Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "geojson_data = 'https://earthquake.usgs.gov/earthquakes/feed/v1.0/summary/4.5_month.geojson'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-12T22:00:49.090751Z",
     "start_time": "2020-08-12T22:00:48.451990Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "response = requests.get(geojson_data).json()\n",
    "features = response[\"features\"]\n",
    "test = features[0]['properties']\n",
    "coords_list = []\n",
    "for data in features:\n",
    "    time = data['properties']['time']\n",
    "    magnitude = data['properties']['mag']\n",
    "    place = data['properties']['place']\n",
    "    \n",
    "    \n",
    "    long_coords = data[\"geometry\"][\"coordinates\"][0]\n",
    "    lat_coords = data[\"geometry\"][\"coordinates\"][1]\n",
    "    \n",
    "    \n",
    "    coords = {\n",
    "            'lat': lat_coords,\n",
    "            'lng': long_coords,\n",
    "            'time': time,\n",
    "            'magnitude': magnitude,\n",
    "            'place': place}\n",
    "    \n",
    "    coords_list.append(coords)\n",
    "pprint(coords_list)\n",
    "# coords_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-12T21:55:26.370949Z",
     "start_time": "2020-08-12T21:55:26.366955Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "len(coords_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Use Coordinates to get historical weather data.\n",
    "Coordinates represent earthquake lat long location"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "This section creates the table WeatherSeries in the database. WeatherSeries has 4 day weather forecast and matching earthquake data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-12T21:14:58.700899Z",
     "start_time": "2020-08-12T21:14:58.696934Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dt3 = datetime.fromtimestamp(1597252395896 / 1000)\n",
    "dt3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-12T22:32:22.520913Z",
     "start_time": "2020-08-12T22:32:22.517920Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-12T22:36:32.714172Z",
     "start_time": "2020-08-12T22:32:48.703937Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pbar = tqdm(total=len(coords_list))\n",
    "\n",
    "tuple_of_data = []\n",
    "add_tuple = {}\n",
    "counter = 0\n",
    "\n",
    "def checkForTwo(number):\n",
    "#     if (int(number)) <= 1:\n",
    "#         number = '1'\n",
    "    if (int(number)) < 10:\n",
    "        number = \"0\" + str(number)\n",
    "    else:\n",
    "#         print(number)\n",
    "        number = str(number)\n",
    "        pass\n",
    "    return number\n",
    "\n",
    "\n",
    "\n",
    "for coordinates in coords_list:\n",
    "    # Lat / long\n",
    "    coords = {coordinates['lat'],coordinates['lng']}\n",
    "    ######################\n",
    "    ## Earthquake time conversion\n",
    "    ######################\n",
    "    earthquake_time = coordinates['time']\n",
    "    dt3 = datetime.fromtimestamp(earthquake_time / 1000)\n",
    "    # Time range end is the day of the earthquake\n",
    "    time_range_end = str(dt3.year) + \"-\" + checkForTwo(dt3.month) + \"-\" + checkForTwo(dt3.day)\n",
    "    \n",
    "    # Time range begin is 3 days before the earthquake\n",
    "    four_day_series = dt3 - timedelta(3)\n",
    "    four_day_day = dt3.day\n",
    "    time_range_begin = str(dt3.year) + \"-\" + checkForTwo(dt3.month) + \"-\" + checkForTwo(four_day_day)\n",
    "#     print(time_range_begin)\n",
    "    \n",
    "    base_url = 'http://api.weatherstack.com/historical'\n",
    "    params_weather = {'access_key': weather_api_key, \n",
    "                    'query': coords,\n",
    "                    'historical_date_start': time_range_begin,\n",
    "                    'historical_date_end': time_range_end\n",
    "                 }\n",
    "    response = requests.get(base_url, params=params_weather).json()\n",
    "    try: \n",
    "        \n",
    "        # extract results\n",
    "        location = response.get('location')\n",
    "#         print(location)\n",
    "        # City, Country, Region\n",
    "        city = location[\"name\"]\n",
    "        country = location[\"country\"]\n",
    "        region = location[\"region\"]\n",
    "\n",
    "        # Historical Only\n",
    "        historical = response['historical']\n",
    "#         print(region)\n",
    "        for hist in historical:\n",
    "            add_tuple = {\n",
    "                'city': location.get('name'),\n",
    "                'country': location[\"country\"],\n",
    "                'region': location[\"region\"],\n",
    "                'avgtemp': historical[hist]['avgtemp'],\n",
    "                'date': historical[hist]['date'],\n",
    "                'date_epoch': historical[hist]['date_epoch'],\n",
    "                'maxtemp': historical[hist]['maxtemp'],\n",
    "                'mintemp': historical[hist]['mintemp'],\n",
    "                'sunhour': historical[hist]['sunhour'],\n",
    "                'totalsnow': historical[hist]['totalsnow'],\n",
    "                'uv_index': historical[hist]['uv_index'],\n",
    "                'long': coordinates['lng'],\n",
    "                'lat': coordinates['lat'],\n",
    "                'time': time,\n",
    "                'magnitude': magnitude,\n",
    "                'place': place}\n",
    "            \n",
    "            pbar.update(1)\n",
    "        tuple_of_data.append(add_tuple)\n",
    "\n",
    "    except TypeError as e:\n",
    "        pbar.update(1)\n",
    "#         print(e)\n",
    "        continue\n",
    "    pbar.update(1)\n",
    "    counter += 1  \n",
    "#     print(counter)\n",
    "pbar.close() \n",
    "#     break\n",
    "# tuple_of_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-12T22:37:19.061185Z",
     "start_time": "2020-08-12T22:37:19.057194Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "len(tuple_of_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Saving to JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-12T22:37:21.317355Z",
     "start_time": "2020-08-12T22:37:21.313367Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "now = datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-12T22:37:22.827111Z",
     "start_time": "2020-08-12T22:37:22.811130Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Get time\n",
    "timedate = now.strftime(\"%Y-%m-%d_%H_%M_%S\")\n",
    "\n",
    "# SAVE: Player_position\n",
    "with open(f'../{timedate}_4_day_weather_for_earthquakes.json', 'w') as fp:\n",
    "    json.dump(tuple_of_data, fp)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-12T04:30:39.823527Z",
     "start_time": "2020-08-12T04:30:39.820507Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# del tuple_of_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Opening JSON .. Do not have to run the api again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-13T03:16:23.557310Z",
     "start_time": "2020-08-13T03:16:23.553285Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Open raw json to parse\n",
    "with open('../2020-08-12_15_37_21_4_day_weather_for_earthquakes.json', 'r') as f:\n",
    "    weather_earthquake_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-13T03:16:23.762070Z",
     "start_time": "2020-08-13T03:16:23.756086Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Dataframe to see raw(cleaned) data\n",
    "all_logs = pd.DataFrame(weather_earthquake_data)\n",
    "# all_logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload to PostgreSQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-13T03:16:26.996219Z",
     "start_time": "2020-08-13T03:16:26.993255Z"
    }
   },
   "outputs": [],
   "source": [
    "# Use this to clear out the db\n",
    "# ----------------------------------\n",
    "# # Session.rollback(self)\n",
    "# Base.metadata.drop_all(engine)\n",
    "# session.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-13T03:16:27.688318Z",
     "start_time": "2020-08-13T03:16:27.685319Z"
    }
   },
   "outputs": [],
   "source": [
    "# del WeatherSeries\n",
    "# del LatLong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-13T03:16:29.214940Z",
     "start_time": "2020-08-13T03:16:29.111188Z"
    }
   },
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "# ----------------------------------\n",
    "# Imports the method used for connecting to DBs\n",
    "from sqlalchemy import create_engine\n",
    "# Allow us to declare column types\n",
    "from sqlalchemy import Column, Integer, String, Text, DateTime, Float, Boolean, ForeignKey\n",
    "from sqlalchemy.orm import relationship\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "from sqlalchemy.orm import Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-13T03:16:30.158345Z",
     "start_time": "2020-08-13T03:16:30.156345Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create Weather and Earthquake Classes\n",
    "# ----------------------------------\n",
    "# Sets an object to utilize the default declarative base in SQL Alchemy\n",
    "Base = declarative_base()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-13T03:16:31.504498Z",
     "start_time": "2020-08-13T03:16:31.495523Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "class LatLong(Base):\n",
    "    __tablename__ = 'latlong'\n",
    "    id = Column(Integer, primary_key=True)\n",
    "    lat = Column(String(12))\n",
    "    long = Column(String(12))\n",
    "    \n",
    "    \n",
    "#     lat_rel = Column(Integer, ForeignKey('weatherSeries.id'))\n",
    "#     weatherSer = relationship(WeatherSeries, primaryjoin=lat_rel == WeatherSeries.id)\n",
    "\n",
    "class WeatherSeries(Base):\n",
    "    __tablename__ = 'weatherSeries'\n",
    "\n",
    "    id = Column(Integer, primary_key=True)\n",
    "    city = Column(String(50))\n",
    "    country = Column(String(200))\n",
    "    region = Column(String(80))\n",
    "    avgtemp = Column(Float)\n",
    "    date = Column(String(12))\n",
    "    date_epoch = Column(Float)\n",
    "    maxtemp = Column(Float)\n",
    "    mintemp = Column(Float)\n",
    "    sunhour = Column(Float)\n",
    "    totalsnow = Column(Float)\n",
    "    uv_index = Column(Float)\n",
    "    lat = Column(String(12))\n",
    "    long = Column(String(12))\n",
    "    \n",
    "\n",
    "#     latlong_id = Column(String,ForeignKey('latlong.id'))\n",
    "#     latlong_rel = relationship(LatLong)\n",
    "    #     lat = Column(String(12))\n",
    "    #     long = Column(String(12))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-13T03:16:33.332073Z",
     "start_time": "2020-08-13T03:16:33.299117Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create Database Connection\n",
    "# ----------------------------------\n",
    "# Creates a connection to our DB\n",
    "# Engine opens the door. Conn is the walk through sign\n",
    "engine = create_engine(\"sqlite:///earthquake_weather.sqlite\")\n",
    "conn = engine.connect()\n",
    "# Create a \"Metadata\" Layer That Abstracts our SQL Database\n",
    "# ----------------------------------\n",
    "# Create (if not already in existence) the tables associated with our classes.\n",
    "Base.metadata.create_all(engine)\n",
    "# Create a Session Object to Connect to DB\n",
    "# ----------------------------------\n",
    "session = Session(bind=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-13T03:16:39.374072Z",
     "start_time": "2020-08-13T03:16:37.176238Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Add weather series to sql\n",
    "x=0\n",
    "while x <= (len(all_logs) - 1):    \n",
    "    lat_long_data = LatLong(\n",
    "        lat = all_logs[\"lat\"][x],\n",
    "        long = all_logs[\"long\"][x]\n",
    "        )\n",
    "    x+=1\n",
    "    # Add Records to the Appropriate DB\n",
    "    # ----------------------------------\n",
    "    # Use the SQL ALchemy methods to run simple \"INSERT\" statements using the classes and objects  \n",
    "    session.add(lat_long_data)\n",
    "    # session.add(earthquake_data)\n",
    "    session.commit()\n",
    "print('Complete: Uploaded to SQLite DB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-13T03:16:39.381027Z",
     "start_time": "2020-08-13T03:16:39.375043Z"
    }
   },
   "outputs": [],
   "source": [
    "## Add weather series to sql\n",
    "def addToSQL(all_logs):\n",
    "    x=0\n",
    "    while x <= (len(all_logs) - 1):\n",
    "        try: \n",
    "            weather_data = WeatherSeries(\n",
    "                city = all_logs[\"city\"][x],\n",
    "                country = all_logs[\"country\"][x],\n",
    "                region = all_logs[\"region\"][x],\n",
    "                avgtemp = all_logs[\"avgtemp\"][x],\n",
    "                date = all_logs[\"date\"][x],\n",
    "                date_epoch = all_logs[\"date_epoch\"][x],\n",
    "                maxtemp = all_logs[\"maxtemp\"][x],\n",
    "                mintemp = all_logs[\"mintemp\"][x],\n",
    "                sunhour = all_logs[\"sunhour\"][x],\n",
    "                totalsnow = all_logs[\"totalsnow\"][x],\n",
    "                uv_index = all_logs[\"uv_index\"][x],\n",
    "                lat = all_logs[\"lat\"][x],\n",
    "                long = all_logs[\"long\"][x],\n",
    "                )\n",
    "            x+=1\n",
    "        except OperationalError:\n",
    "            pass\n",
    "            \n",
    "        # Add Records to the Appropriate DB\n",
    "        # ----------------------------------\n",
    "        # Use the SQL ALchemy methods to run simple \"INSERT\" statements using the classes and objects  \n",
    "        session.add(weather_data)\n",
    "        # session.add(earthquake_data)\n",
    "        session.commit()\n",
    "    return 'Complete: Uploaded to SQLite DB'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-13T03:16:41.952082Z",
     "start_time": "2020-08-13T03:16:39.573527Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "addToSQL(all_logs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-13T03:22:55.726376Z",
     "start_time": "2020-08-13T03:22:55.723383Z"
    }
   },
   "outputs": [],
   "source": [
    "# Python SQL toolkit and Object Relational Mapper\n",
    "import sqlalchemy\n",
    "# Go to existing database with automap_base\n",
    "from sqlalchemy.ext.automap import automap_base\n",
    "# Work through mapper to use python code\n",
    "from sqlalchemy.orm import Session\n",
    "# Inspect with python\n",
    "from sqlalchemy import create_engine, inspect\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-13T03:41:38.839638Z",
     "start_time": "2020-08-13T03:41:38.834679Z"
    }
   },
   "outputs": [],
   "source": [
    "def weatherTimeSeries(query_call):\n",
    "    Base = automap_base()\n",
    "    Base.prepare(engine, reflect=True)\n",
    "#     Base.classes.keys()\n",
    "    weather_table = Base.classes.weatherSeries\n",
    "    weather_container = session.query(weather_table).filter(weather_table.date == query_call).all()\n",
    "    weather_data = []\n",
    "    for data in weather_container:\n",
    "        container = {\n",
    "            \"Date\": {data.date}, \n",
    "            \"Lat\": {data.lat}, \n",
    "            \"Long\": {data.long}, \n",
    "            \"MaxTemp\": {data.maxtemp}\n",
    "        }\n",
    "        weather_data.append(container)\n",
    "    return test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-13T03:42:25.717850Z",
     "start_time": "2020-08-13T03:42:25.706880Z"
    }
   },
   "outputs": [],
   "source": [
    "date = '2020-08-12'\n",
    "thisHoldsMyData = weatherTimeSeries(date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# latlong_container = session.query(latlong_table).filter(latlong_table.lat == '').all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-13T03:18:50.959907Z",
     "start_time": "2020-08-13T03:18:50.956886Z"
    }
   },
   "outputs": [],
   "source": [
    "# for data in latlong_table:\n",
    "#     print(f\"Date: {data.lat}, Temp: {data.long}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-13T03:17:44.639252Z",
     "start_time": "2020-08-13T03:17:44.635284Z"
    }
   },
   "outputs": [],
   "source": [
    "# def join_example():\n",
    "#     records = session.query(WeatherSeries).\\\n",
    "#         join(LatLong, LatLong.id == WeatherSeries.id).all()\n",
    "# #     print(records)\n",
    "#     for record in records:\n",
    "#         recordObject = {\n",
    "#             'city': record.city,\n",
    "#             'country': record.country,\n",
    "#             'date': record.date,\n",
    "#             'maxtemp': record.maxtemp,\n",
    "#             'latlong_rel': record.latlong_rel\n",
    "#         }\n",
    "#         print(recordObject)\n",
    "# join_example()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-13T03:17:46.704843Z",
     "start_time": "2020-08-13T03:17:46.682893Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create DataFrame from sql table Weather\n",
    "weather_data_df = pd.read_sql(\"SELECT * FROM WeatherSeries\", conn)\n",
    "weather_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-13T03:10:23.766957Z",
     "start_time": "2020-08-13T03:10:23.751969Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create DataFrame from sql table Weather\n",
    "weather_data_df = pd.read_sql(\"SELECT * FROM LatLong\", conn)\n",
    "weather_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### \n",
    "## KEEP !!\n",
    "## DO NOT DELETE ALL THIS\n",
    "###\n",
    "\n",
    "# Create a Specific Instance of the \"weather_data\" and \"earthquake_data\" classes\n",
    "# ----------------------------------\n",
    "# Data needs to pass through this. A for loop while need to be created to consistantly send multiple files\n",
    "# weather_data = WeatherSeries(\n",
    "#     lat = '',\n",
    "#     lon = '',\n",
    "#     date = '',\n",
    "#     city = '',\n",
    "#     country = '',\n",
    "#     region = '',\n",
    "#     avgtemp = '',\n",
    "#     date_epoch = '',\n",
    "#     maxtemp = '',\n",
    "#     mintemp = '',\n",
    "#     sunhour = '',\n",
    "#     totalsnow = '',\n",
    "#     uv_index = '',\n",
    "#     )\n",
    "\n",
    "# earthquake_data = Earthquake(\n",
    "#     lat = '',\n",
    "#     lon = '',\n",
    "#     date = '',\n",
    "#     mag = '',\n",
    "#     location = ''\n",
    "#     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-12T10:27:56.043030Z",
     "start_time": "2020-08-12T10:27:56.040038Z"
    }
   },
   "outputs": [],
   "source": [
    "# def checkEqual3(lst):\n",
    "#     return lst[1:] == lst[:-1]\n",
    "\n",
    "# def checkRowValueDups(data):\n",
    "#     dictOfKeys = data.keys()\n",
    "#     for column in data:\n",
    "#         column_values = data[column].to_list()\n",
    "#         result = checkEqual3(column_values)\n",
    "# #         print('passed.')\n",
    "#     if result == True:\n",
    "#         all_logs_df = all_logs.iloc[0:1, 0:]\n",
    "#     else:\n",
    "#         print(\"Couldnt complete cleaning. Different value found in column where only duplicates live. Check function checkRowValueDups() for information\")\n",
    "#     return all_logs_df\n",
    "\n",
    "# all_logs_df = checkRowValueDups(all_logs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-12T10:27:58.503194Z",
     "start_time": "2020-08-12T10:27:58.500244Z"
    }
   },
   "outputs": [],
   "source": [
    "# all_logs_df['2020-08-03'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stuff = (list(all_logs.itertuples(index=False, name=None)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.7 64-bit ('usc_bootcamp': conda)",
   "language": "python",
   "name": "python37764bituscbootcampconda3361b9ec87e5404d80e03b8fe2fcfaaf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
