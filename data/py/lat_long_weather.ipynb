{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-17T22:02:55.108543Z",
     "start_time": "2020-08-17T22:02:55.104582Z"
    }
   },
   "outputs": [],
   "source": [
    "# Dependencies and Setup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from pprint import pprint\n",
    "import requests\n",
    "from datetime import date, timedelta, datetime\n",
    "import json\n",
    "# Import API key\n",
    "from config import weather_api_key\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-11T23:36:29.183999Z",
     "start_time": "2020-08-11T23:36:29.180008Z"
    },
    "heading_collapsed": true
   },
   "source": [
    "### Get Long Lat list of tuples to pass into Weather API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-17T22:02:57.348708Z",
     "start_time": "2020-08-17T22:02:57.345700Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "geojson_data = 'https://earthquake.usgs.gov/earthquakes/feed/v1.0/summary/4.5_month.geojson'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-17T22:02:57.698260Z",
     "start_time": "2020-08-17T22:02:57.592543Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "response = requests.get(geojson_data).json()\n",
    "features = response[\"features\"]\n",
    "test = features[0]['properties']\n",
    "coords_list = []\n",
    "for data in features:\n",
    "    time = data['properties']['time']\n",
    "    magnitude = data['properties']['mag']\n",
    "    place = data['properties']['place']\n",
    "    \n",
    "    long_coords = data[\"geometry\"][\"coordinates\"][0]\n",
    "    lat_coords = data[\"geometry\"][\"coordinates\"][1]\n",
    "    \n",
    "    coords = {\n",
    "            'latlng': f\"{lat_coords}, {long_coords}\",\n",
    "            'lat': lat_coords,\n",
    "            'long': long_coords,\n",
    "            'time': time,\n",
    "            'magnitude': magnitude,\n",
    "            'place': place}\n",
    "    \n",
    "    coords_list.append(coords)\n",
    "# pprint(coords_list)\n",
    "# coords_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-17T22:02:58.853221Z",
     "start_time": "2020-08-17T22:02:58.849272Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "len(coords_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Use Coordinates to get historical weather data.\n",
    "Coordinates represent earthquake lat long location"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "This section creates the table WeatherSeries in the database. WeatherSeries has 4 day weather forecast and matching earthquake data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-17T22:03:18.860124Z",
     "start_time": "2020-08-17T22:03:18.857132Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-17T22:11:14.980459Z",
     "start_time": "2020-08-17T22:05:12.104996Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pbar = tqdm(total=len(coords_list))\n",
    "\n",
    "tuple_of_data = []\n",
    "add_tuple = {}\n",
    "counter = 0\n",
    "\n",
    "def checkForTwo(number):\n",
    "#     if (int(number)) <= 1:\n",
    "#         number = '1'\n",
    "    if (int(number)) < 10:\n",
    "        number = \"0\" + str(number)\n",
    "    else:\n",
    "#         print(number)\n",
    "        number = str(number)\n",
    "        pass\n",
    "    return number\n",
    "\n",
    "for coordinates in coords_list:\n",
    "    # Lat / long\n",
    "    coords = coordinates['latlng']\n",
    "    \n",
    "    ######################\n",
    "    ## Earthquake time conversion\n",
    "    ######################\n",
    "    earthquake_time = coordinates['time']\n",
    "    dt3 = datetime.fromtimestamp(earthquake_time / 1000)\n",
    "    # Time range end is the day of the earthquake\n",
    "    time_range_end = str(dt3.year) + \"-\" + checkForTwo(dt3.month) + \"-\" + checkForTwo(dt3.day)\n",
    "    \n",
    "    # Time range begin is 3 days before the earthquake\n",
    "    four_day_series = dt3 - timedelta(3)\n",
    "    four_day_day = four_day_series\n",
    "    time_range_begin = str(dt3.year) + \"-\" + checkForTwo(dt3.month) + \"-\" + checkForTwo(four_day_day.day)\n",
    "    ######################\n",
    "    \n",
    "    base_url = 'http://api.weatherstack.com/historical'\n",
    "    params_weather = {'access_key': weather_api_key, \n",
    "                    'query': coords,\n",
    "                    'historical_date_start': time_range_begin,\n",
    "                    'historical_date_end': time_range_end,\n",
    "                    'units': 'f'\n",
    "                 }\n",
    "    \n",
    "    response = requests.get(base_url, params=params_weather).json()\n",
    "    # url_link = requests.get(base_url, params=params_weather).url\n",
    "    \n",
    "    try: \n",
    "        # extract results\n",
    "        location = response.get('location')\n",
    "        # City, Country, Region\n",
    "        city = location[\"name\"]\n",
    "        country = location[\"country\"]\n",
    "        region = location[\"region\"]\n",
    "\n",
    "        # Historical Only\n",
    "        historical = response['historical']\n",
    "#         print(region)\n",
    "        for hist in historical:\n",
    "            add_tuple = {\n",
    "                'city': city,\n",
    "                'country': country,\n",
    "                'region': region,\n",
    "                'avgtemp': historical[hist]['avgtemp'],\n",
    "                'date': historical[hist]['date'],\n",
    "                'date_epoch': historical[hist]['date_epoch'],\n",
    "                'maxtemp': historical[hist]['maxtemp'],\n",
    "                'mintemp': historical[hist]['mintemp'],\n",
    "                'sunhour': historical[hist]['sunhour'],\n",
    "                'totalsnow': historical[hist]['totalsnow'],\n",
    "                'uv_index': historical[hist]['uv_index'],\n",
    "                'long': coordinates['long'],\n",
    "                'lat': coordinates['lat'],\n",
    "                'time': coordinates['time'],\n",
    "                'magnitude': coordinates['magnitude'],\n",
    "                'place': coordinates['place']\n",
    "            }\n",
    "            tuple_of_data.append(add_tuple)\n",
    "            pbar.update(1)\n",
    "    except TypeError as e:\n",
    "\n",
    "    # print(e)\n",
    "        continue\n",
    "    pbar.update(1)\n",
    "    counter += 1\n",
    "\n",
    "pbar.close() \n",
    "\n",
    "# tuple_of_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-17T22:15:39.416885Z",
     "start_time": "2020-08-17T22:15:39.411897Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "len(tuple_of_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Saving to JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-17T22:15:40.951060Z",
     "start_time": "2020-08-17T22:15:40.948058Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "now = datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-17T22:15:42.460761Z",
     "start_time": "2020-08-17T22:15:42.389833Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Get time\n",
    "timedate = now.strftime(\"%Y-%m-%d_%H_%M_%S\")\n",
    "\n",
    "# SAVE: Player_position\n",
    "with open(f'../{timedate}_4_day_weather_for_earthquakes.json', 'w') as fp:\n",
    "    json.dump(tuple_of_data, fp)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-12T04:30:39.823527Z",
     "start_time": "2020-08-12T04:30:39.820507Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# del tuple_of_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Opening JSON .. Do not have to run the api again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-17T22:16:07.166731Z",
     "start_time": "2020-08-17T22:16:07.153731Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Open raw json to parse\n",
    "with open('../2020-08-17_15_15_40_4_day_weather_for_earthquakes.json', 'r') as f:\n",
    "    weather_earthquake_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-17T22:16:10.456725Z",
     "start_time": "2020-08-17T22:16:10.448778Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Dataframe to see raw(cleaned) data\n",
    "all_logs = pd.DataFrame(weather_earthquake_data)\n",
    "# all_logs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-13T17:05:49.615599Z",
     "start_time": "2020-08-13T17:05:49.595652Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload to PostgreSQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-17T22:16:31.551675Z",
     "start_time": "2020-08-17T22:16:31.547662Z"
    }
   },
   "outputs": [],
   "source": [
    "# Use this to clear out the db\n",
    "# ----------------------------------\n",
    "# # Session.rollback(self)\n",
    "# Base.metadata.drop_all(engine)\n",
    "# session.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-17T22:16:32.372963Z",
     "start_time": "2020-08-17T22:16:32.369969Z"
    }
   },
   "outputs": [],
   "source": [
    "# Delete previous entries\n",
    "# del WeatherSeries\n",
    "# del LatLong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T03:24:22.053149Z",
     "start_time": "2020-08-18T03:24:21.695354Z"
    }
   },
   "outputs": [],
   "source": [
    "# Dependencies and Setup\n",
    "import pandas as pd\n",
    "# import numpy as np\n",
    "# import time\n",
    "\n",
    "# import requests\n",
    "from datetime import date, timedelta, datetime\n",
    "import json\n",
    "# Import API key\n",
    "# from config import weather_api_key\n",
    "# from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T03:24:22.175746Z",
     "start_time": "2020-08-18T03:24:22.054057Z"
    }
   },
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "# ----------------------------------\n",
    "# Imports the method used for connecting to DBs\n",
    "from sqlalchemy import create_engine\n",
    "# Allow us to declare column types\n",
    "from sqlalchemy import Column, Integer, String, Text, DateTime, Float, Boolean, ForeignKey\n",
    "from sqlalchemy.orm import relationship\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "from sqlalchemy.orm import Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T03:24:22.195501Z",
     "start_time": "2020-08-18T03:24:22.192478Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create Weather and Earthquake Classes\n",
    "# ----------------------------------\n",
    "# Sets an object to utilize the default declarative base in SQL Alchemy\n",
    "Base = declarative_base()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T03:24:22.408067Z",
     "start_time": "2020-08-18T03:24:22.400117Z"
    }
   },
   "outputs": [],
   "source": [
    "## Class base template to upload to sqlite\n",
    "class WeatherSeries(Base):\n",
    "    __tablename__ = 'weatherSeries'\n",
    "\n",
    "    id = Column(Integer, primary_key=True)\n",
    "    city = Column(String(50))\n",
    "    country = Column(String(200))\n",
    "    region = Column(String(80))\n",
    "    avgtemp = Column(Float)\n",
    "    date = Column(String(12))\n",
    "    date_epoch = Column(Float)\n",
    "    maxtemp = Column(Float)\n",
    "    mintemp = Column(Float)\n",
    "    sunhour = Column(Float)\n",
    "    totalsnow = Column(Float)\n",
    "    uv_index = Column(Float)\n",
    "    magnitude = Column(Float)\n",
    "    place = Column(String(80))\n",
    "    lat = Column(String(12))\n",
    "    long = Column(String(12))\n",
    "    \n",
    "# class LatLong(Base):\n",
    "#     __tablename__ = 'latlong'\n",
    "#     id = Column(Integer, primary_key=True)\n",
    "#     lat = Column(String(12))\n",
    "#     long = Column(String(12))\n",
    "#     lat_rel = Column(Integer, ForeignKey('weatherSeries.id'))\n",
    "#     weatherSer = relationship(WeatherSeries, primaryjoin=lat_rel == WeatherSeries.id)\n",
    "#     latlong_id = Column(String,ForeignKey('latlong.id'))\n",
    "#     latlong_rel = relationship(LatLong)\n",
    "#     lat = Column(String(12))\n",
    "#     long = Column(String(12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T03:24:23.250875Z",
     "start_time": "2020-08-18T03:24:23.239834Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create Database Connection\n",
    "# ----------------------------------\n",
    "# Creates a connection to our DB\n",
    "# Engine opens the door. Conn is the walk through sign\n",
    "engine = create_engine(\"sqlite:///earthquake_weather.sqlite\")\n",
    "conn = engine.connect()\n",
    "# Create a \"Metadata\" Layer That Abstracts our SQL Database\n",
    "# ----------------------------------\n",
    "# Create (if not already in existence) the tables associated with our classes.\n",
    "Base.metadata.create_all(engine)\n",
    "# Create a Session Object to Connect to DB\n",
    "# ----------------------------------\n",
    "session = Session(bind=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-17T22:16:36.164459Z",
     "start_time": "2020-08-17T22:16:36.161467Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ## Add weather series to sql\n",
    "# x=0\n",
    "# while x <= (len(all_logs) - 1):    \n",
    "#     lat_long_data = LatLong(\n",
    "#         lat = all_logs[\"lat\"][x],\n",
    "#         long = all_logs[\"long\"][x]\n",
    "#         )\n",
    "#     x+=1\n",
    "#     # Add Records to the Appropriate DB\n",
    "#     # ----------------------------------\n",
    "#     # Use the SQL ALchemy methods to run simple \"INSERT\" statements using the classes and objects  \n",
    "#     session.add(lat_long_data)\n",
    "#     # session.add(earthquake_data)\n",
    "#     session.commit()\n",
    "# print('Complete: Uploaded to SQLite DB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-17T22:16:37.204498Z",
     "start_time": "2020-08-17T22:16:37.198482Z"
    }
   },
   "outputs": [],
   "source": [
    "## Function: Add Weather Series to sql\n",
    "def addToSQL(all_logs):\n",
    "    x=0\n",
    "    while x <= (len(all_logs) - 1):\n",
    "        try: \n",
    "            weather_data = WeatherSeries(\n",
    "                city = all_logs[\"city\"][x],\n",
    "                country = all_logs[\"country\"][x],\n",
    "                region = all_logs[\"region\"][x],\n",
    "                avgtemp = all_logs[\"avgtemp\"][x],\n",
    "                date = all_logs[\"date\"][x],\n",
    "                date_epoch = all_logs[\"date_epoch\"][x],\n",
    "                maxtemp = all_logs[\"maxtemp\"][x],\n",
    "                mintemp = all_logs[\"mintemp\"][x],\n",
    "                sunhour = all_logs[\"sunhour\"][x],\n",
    "                totalsnow = all_logs[\"totalsnow\"][x],\n",
    "                uv_index = all_logs[\"uv_index\"][x],\n",
    "                magnitude = all_logs[\"magnitude\"][x],\n",
    "                place = all_logs[\"place\"][x],\n",
    "                lat = all_logs[\"lat\"][x],\n",
    "                long = all_logs[\"long\"][x],\n",
    "                )\n",
    "            x+=1\n",
    "        except OperationalError:\n",
    "            pass\n",
    "            \n",
    "        # Add Records to the Appropriate DB\n",
    "        # ----------------------------------\n",
    "        # Use the SQL ALchemy methods to run simple \"INSERT\" statements using the classes and objects  \n",
    "        session.add(weather_data)\n",
    "        # session.add(earthquake_data)\n",
    "        session.commit()\n",
    "    return 'Complete: Uploaded to SQLite DB'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-17T22:16:51.105872Z",
     "start_time": "2020-08-17T22:16:38.406908Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "addToSQL(all_logs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query from DB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DataFrame "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T03:24:26.020599Z",
     "start_time": "2020-08-18T03:24:25.987315Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>city</th>\n",
       "      <th>country</th>\n",
       "      <th>region</th>\n",
       "      <th>avgtemp</th>\n",
       "      <th>date</th>\n",
       "      <th>date_epoch</th>\n",
       "      <th>maxtemp</th>\n",
       "      <th>mintemp</th>\n",
       "      <th>sunhour</th>\n",
       "      <th>totalsnow</th>\n",
       "      <th>uv_index</th>\n",
       "      <th>magnitude</th>\n",
       "      <th>place</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>El Azufre</td>\n",
       "      <td>Mexico</td>\n",
       "      <td>Oaxaca</td>\n",
       "      <td>84.0</td>\n",
       "      <td>2020-08-14</td>\n",
       "      <td>1.597363e+09</td>\n",
       "      <td>88.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>10.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.8</td>\n",
       "      <td>127 km SSW of Santa María Chico Ometepec, Mexico</td>\n",
       "      <td>15.0758</td>\n",
       "      <td>-98.3289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>El Azufre</td>\n",
       "      <td>Mexico</td>\n",
       "      <td>Oaxaca</td>\n",
       "      <td>82.0</td>\n",
       "      <td>2020-08-15</td>\n",
       "      <td>1.597450e+09</td>\n",
       "      <td>86.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>10.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.8</td>\n",
       "      <td>127 km SSW of Santa María Chico Ometepec, Mexico</td>\n",
       "      <td>15.0758</td>\n",
       "      <td>-98.3289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>El Azufre</td>\n",
       "      <td>Mexico</td>\n",
       "      <td>Oaxaca</td>\n",
       "      <td>82.0</td>\n",
       "      <td>2020-08-16</td>\n",
       "      <td>1.597536e+09</td>\n",
       "      <td>86.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>6.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.8</td>\n",
       "      <td>127 km SSW of Santa María Chico Ometepec, Mexico</td>\n",
       "      <td>15.0758</td>\n",
       "      <td>-98.3289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>El Azufre</td>\n",
       "      <td>Mexico</td>\n",
       "      <td>Oaxaca</td>\n",
       "      <td>82.0</td>\n",
       "      <td>2020-08-17</td>\n",
       "      <td>1.597622e+09</td>\n",
       "      <td>86.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>6.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.8</td>\n",
       "      <td>127 km SSW of Santa María Chico Ometepec, Mexico</td>\n",
       "      <td>15.0758</td>\n",
       "      <td>-98.3289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Las Enramadas</td>\n",
       "      <td>Nicaragua</td>\n",
       "      <td>Chinandega</td>\n",
       "      <td>84.0</td>\n",
       "      <td>2020-08-14</td>\n",
       "      <td>1.597363e+09</td>\n",
       "      <td>90.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>10.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.8</td>\n",
       "      <td>59 km S of Intipucá, El Salvador</td>\n",
       "      <td>12.6645</td>\n",
       "      <td>-88.1243</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id           city    country      region  avgtemp        date  \\\n",
       "0   1      El Azufre     Mexico      Oaxaca     84.0  2020-08-14   \n",
       "1   2      El Azufre     Mexico      Oaxaca     82.0  2020-08-15   \n",
       "2   3      El Azufre     Mexico      Oaxaca     82.0  2020-08-16   \n",
       "3   4      El Azufre     Mexico      Oaxaca     82.0  2020-08-17   \n",
       "4   5  Las Enramadas  Nicaragua  Chinandega     84.0  2020-08-14   \n",
       "\n",
       "     date_epoch  maxtemp  mintemp  sunhour  totalsnow  uv_index  magnitude  \\\n",
       "0  1.597363e+09     88.0     77.0     10.2        0.0       7.0        4.8   \n",
       "1  1.597450e+09     86.0     77.0     10.2        0.0       6.0        4.8   \n",
       "2  1.597536e+09     86.0     77.0      6.2        0.0       6.0        4.8   \n",
       "3  1.597622e+09     86.0     75.0      6.2        0.0       6.0        4.8   \n",
       "4  1.597363e+09     90.0     77.0     10.6        0.0       7.0        4.8   \n",
       "\n",
       "                                              place      lat      long  \n",
       "0  127 km SSW of Santa María Chico Ometepec, Mexico  15.0758  -98.3289  \n",
       "1  127 km SSW of Santa María Chico Ometepec, Mexico  15.0758  -98.3289  \n",
       "2  127 km SSW of Santa María Chico Ometepec, Mexico  15.0758  -98.3289  \n",
       "3  127 km SSW of Santa María Chico Ometepec, Mexico  15.0758  -98.3289  \n",
       "4                  59 km S of Intipucá, El Salvador  12.6645  -88.1243  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verify Data \n",
    "# Create DataFrame from sql table Weather\n",
    "weather_data_df = pd.read_sql(\"SELECT * FROM WeatherSeries\", conn)\n",
    "weather_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T03:24:30.857201Z",
     "start_time": "2020-08-18T03:24:30.854208Z"
    }
   },
   "outputs": [],
   "source": [
    "# avg = weather_data_df[weather_data_df['magnitude'] > 6.0]\n",
    "# avg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Python call from db. For flask to web"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T03:24:31.931363Z",
     "start_time": "2020-08-18T03:24:31.927435Z"
    }
   },
   "outputs": [],
   "source": [
    "# Python SQL toolkit and Object Relational Mapper\n",
    "import sqlalchemy\n",
    "# Go to existing database with automap_base\n",
    "from sqlalchemy.ext.automap import automap_base\n",
    "# Work through mapper to use python code\n",
    "from sqlalchemy.orm import Session\n",
    "# Inspect with python\n",
    "from sqlalchemy import create_engine, inspect\n",
    "from sqlalchemy import desc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T03:24:32.306839Z",
     "start_time": "2020-08-18T03:24:32.294872Z"
    }
   },
   "outputs": [],
   "source": [
    "Base = automap_base()\n",
    "Base.prepare(engine, reflect=True)\n",
    "# Check db table names\n",
    "# Base.classes.keys()\n",
    "weather_table = Base.classes.weatherSeries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## analysisChartCall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T03:28:54.536883Z",
     "start_time": "2020-08-18T03:28:54.215155Z"
    }
   },
   "outputs": [],
   "source": [
    "Base = automap_base()\n",
    "Base.prepare(engine, reflect=True)\n",
    "weather_table = Base.classes.weatherSeries\n",
    "analysis_container = session.query(weather_table).order_by(desc(weather_table.date)).all()        \n",
    "analysis_list_temp = []\n",
    "x=1\n",
    "\n",
    "for data in analysis_container:\n",
    "    # get specific data from db\n",
    "    container = {\n",
    "        \"date\": data.date,\n",
    "        \"magnitude\": data.magnitude,\n",
    "        \"maxtemp\": data.maxtemp,\n",
    "        \"mintemp\": data.mintemp,\n",
    "#         \"avgtemp\": data.avgtemp,\n",
    "        \"lat\": data.lat,\n",
    "        }\n",
    "    analysis_list_temp.append(container)\n",
    "\n",
    "# Create df for parsing    \n",
    "temp_df = pd.DataFrame(analysis_list_temp)\n",
    "# Sort by lat and date, reset index\n",
    "temp_df = temp_df.sort_values(by=['lat', 'date'], ascending=False).reset_index(drop=True)\n",
    "\n",
    "# Make copy of df, remove 2nd and 3rd log keeping 1st and 4th log of one eq entry.\n",
    "run_df = temp_df.copy()\n",
    "while x < len(temp_df.index):\n",
    "    run_df=run_df.drop(x)\n",
    "    x+=1\n",
    "    run_df=run_df.drop(x)\n",
    "    x+=3\n",
    "\n",
    "# Reset index \n",
    "run_df = run_df.reset_index(drop=True) \n",
    "\n",
    "# get difference of weather change from day of eq and few days before\n",
    "i = 0\n",
    "new_col = []\n",
    "# Icon list will tell style which icon to display\n",
    "icon_list = []\n",
    "while i < len(run_df.index):\n",
    "#     for data in run_df.index:\n",
    "    first = run_df.iloc[i,2]\n",
    "    second = run_df.iloc[i+1, 2]\n",
    "    difference = first - second\n",
    "    new_col.append(difference)\n",
    "    new_col.append(difference)\n",
    "    i+=2    \n",
    "# Add new list to df as a new column  \n",
    "run_df['difference'] = new_col     \n",
    "for x in run_df['difference']:\n",
    "    if x > 0:\n",
    "        icon = \"up\"\n",
    "        icon_list.append(icon)\n",
    "    elif x == 0:\n",
    "        icon = \"nochange\"\n",
    "        icon_list.append(icon)\n",
    "    else:\n",
    "        icon = \"down\"\n",
    "        icon_list.append(icon)\n",
    "\n",
    "# Add new list to df as a new column\n",
    "run_df['icon'] = icon_list    \n",
    "# select only the columns we need\n",
    "run_df = run_df[['date','magnitude','lat','difference','icon']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T03:28:54.953843Z",
     "start_time": "2020-08-18T03:28:54.940877Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>magnitude</th>\n",
       "      <th>lat</th>\n",
       "      <th>difference</th>\n",
       "      <th>icon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-07-18</td>\n",
       "      <td>4.8</td>\n",
       "      <td>9.5869</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>down</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-07-15</td>\n",
       "      <td>4.8</td>\n",
       "      <td>9.5869</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>down</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-07-29</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.0332</td>\n",
       "      <td>4.0</td>\n",
       "      <td>up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-07-26</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.0332</td>\n",
       "      <td>4.0</td>\n",
       "      <td>up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-07-27</td>\n",
       "      <td>5.8</td>\n",
       "      <td>9.0127</td>\n",
       "      <td>0.0</td>\n",
       "      <td>nochange</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>741</th>\n",
       "      <td>2020-08-11</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-10.2241</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>down</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>742</th>\n",
       "      <td>2020-08-04</td>\n",
       "      <td>5.1</td>\n",
       "      <td>-1.7797</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>down</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>743</th>\n",
       "      <td>2020-08-01</td>\n",
       "      <td>5.1</td>\n",
       "      <td>-1.7797</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>down</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>744</th>\n",
       "      <td>2020-08-16</td>\n",
       "      <td>4.7</td>\n",
       "      <td>-0.2919</td>\n",
       "      <td>0.0</td>\n",
       "      <td>nochange</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>745</th>\n",
       "      <td>2020-08-13</td>\n",
       "      <td>4.7</td>\n",
       "      <td>-0.2919</td>\n",
       "      <td>0.0</td>\n",
       "      <td>nochange</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>746 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date  magnitude       lat  difference      icon\n",
       "0    2020-07-18        4.8    9.5869        -2.0      down\n",
       "1    2020-07-15        4.8    9.5869        -2.0      down\n",
       "2    2020-07-29        4.5    9.0332         4.0        up\n",
       "3    2020-07-26        4.5    9.0332         4.0        up\n",
       "4    2020-07-27        5.8    9.0127         0.0  nochange\n",
       "..          ...        ...       ...         ...       ...\n",
       "741  2020-08-11        5.0  -10.2241        -4.0      down\n",
       "742  2020-08-04        5.1   -1.7797        -3.0      down\n",
       "743  2020-08-01        5.1   -1.7797        -3.0      down\n",
       "744  2020-08-16        4.7   -0.2919         0.0  nochange\n",
       "745  2020-08-13        4.7   -0.2919         0.0  nochange\n",
       "\n",
       "[746 rows x 5 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T00:13:00.912268Z",
     "start_time": "2020-08-18T00:13:00.898282Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>magnitude</th>\n",
       "      <th>lat</th>\n",
       "      <th>difference</th>\n",
       "      <th>icon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>2020-07-17</td>\n",
       "      <td>4.9</td>\n",
       "      <td>30.4051</td>\n",
       "      <td>-14.0</td>\n",
       "      <td>down</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>2020-07-20</td>\n",
       "      <td>4.9</td>\n",
       "      <td>30.4051</td>\n",
       "      <td>-14.0</td>\n",
       "      <td>down</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>2020-07-17</td>\n",
       "      <td>4.9</td>\n",
       "      <td>30.4402</td>\n",
       "      <td>-14.0</td>\n",
       "      <td>down</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>2020-07-20</td>\n",
       "      <td>4.9</td>\n",
       "      <td>30.4402</td>\n",
       "      <td>-14.0</td>\n",
       "      <td>down</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>2020-08-06</td>\n",
       "      <td>4.9</td>\n",
       "      <td>36.5497</td>\n",
       "      <td>-12.0</td>\n",
       "      <td>down</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>2020-07-21</td>\n",
       "      <td>4.9</td>\n",
       "      <td>30.3884</td>\n",
       "      <td>12.0</td>\n",
       "      <td>up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>2020-08-07</td>\n",
       "      <td>4.5</td>\n",
       "      <td>28.9031</td>\n",
       "      <td>13.0</td>\n",
       "      <td>up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>2020-08-10</td>\n",
       "      <td>4.5</td>\n",
       "      <td>28.9031</td>\n",
       "      <td>13.0</td>\n",
       "      <td>up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>609</th>\n",
       "      <td>2020-08-07</td>\n",
       "      <td>4.5</td>\n",
       "      <td>-23.9032</td>\n",
       "      <td>15.0</td>\n",
       "      <td>up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>608</th>\n",
       "      <td>2020-08-10</td>\n",
       "      <td>4.5</td>\n",
       "      <td>-23.9032</td>\n",
       "      <td>15.0</td>\n",
       "      <td>up</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>746 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date  magnitude       lat  difference  icon\n",
       "255  2020-07-17        4.9   30.4051       -14.0  down\n",
       "254  2020-07-20        4.9   30.4051       -14.0  down\n",
       "243  2020-07-17        4.9   30.4402       -14.0  down\n",
       "242  2020-07-20        4.9   30.4402       -14.0  down\n",
       "180  2020-08-06        4.9   36.5497       -12.0  down\n",
       "..          ...        ...       ...         ...   ...\n",
       "263  2020-07-21        4.9   30.3884        12.0    up\n",
       "297  2020-08-07        4.5   28.9031        13.0    up\n",
       "296  2020-08-10        4.5   28.9031        13.0    up\n",
       "609  2020-08-07        4.5  -23.9032        15.0    up\n",
       "608  2020-08-10        4.5  -23.9032        15.0    up\n",
       "\n",
       "[746 rows x 5 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_df.sort_values(by='difference')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-17T22:00:11.019883Z",
     "start_time": "2020-08-17T22:00:11.005888Z"
    }
   },
   "outputs": [],
   "source": [
    "def analysisChartCall():\n",
    "    # Sets an object to utilize the default declarative base in SQL Alchemy\n",
    "    Base = declarative_base()\n",
    "    ## Class base template to upload to sqlite\n",
    "    class WeatherSeries(Base):\n",
    "        __tablename__ = 'weatherSeries'\n",
    "\n",
    "        id = Column(Integer, primary_key=True)\n",
    "        city = Column(String(50))\n",
    "        country = Column(String(200))\n",
    "        region = Column(String(80))\n",
    "        avgtemp = Column(Float)\n",
    "        date = Column(String(12))\n",
    "        date_epoch = Column(Float)\n",
    "        maxtemp = Column(Float)\n",
    "        mintemp = Column(Float)\n",
    "        sunhour = Column(Float)\n",
    "        totalsnow = Column(Float)\n",
    "        uv_index = Column(Float)\n",
    "        magnitude = Column(Float)\n",
    "        place = Column(String(80))\n",
    "        lat = Column(String(12))\n",
    "        long = Column(String(12))\n",
    "\n",
    "    # Create Database Connection\n",
    "    # ----------------------------------\n",
    "    # Creates a connection to our DB\n",
    "    # Engine opens the door. Conn is the walk through sign\n",
    "    engine = create_engine(\"sqlite:///earthquake_weather.sqlite\")\n",
    "    conn = engine.connect()\n",
    "    # Create a \"Metadata\" Layer That Abstracts our SQL Database\n",
    "    # ----------------------------------\n",
    "    # Create (if not already in existence) the tables associated with our classes.\n",
    "    Base.metadata.create_all(engine)\n",
    "    # Create a Session Object to Connect to DB\n",
    "    # ----------------------------------\n",
    "    session = Session(bind=engine)\n",
    "\n",
    "    def analysisChart():\n",
    "        Base = automap_base()\n",
    "        Base.prepare(engine, reflect=True)\n",
    "        weather_table = Base.classes.weatherSeries\n",
    "        analysis_container = session.query(weather_table).order_by(desc(weather_table.date)).all()        \n",
    "        analysis_list_temp = []\n",
    "        x=1\n",
    "\n",
    "        for data in analysis_container:\n",
    "            # get specific data from db\n",
    "            container = {\n",
    "                \"date\": data.date,\n",
    "                \"magnitude\": data.magnitude,\n",
    "                \"maxtemp\": data.maxtemp,\n",
    "                \"mintemp\": data.mintemp,\n",
    "        #         \"avgtemp\": data.avgtemp,\n",
    "                \"lat\": data.lat,\n",
    "                }\n",
    "            analysis_list_temp.append(container)\n",
    "\n",
    "        # Create df for parsing    \n",
    "        temp_df = pd.DataFrame(analysis_list_temp)\n",
    "        # Sort by lat and date, reset index\n",
    "        temp_df = temp_df.sort_values(by=['lat', 'date'], ascending=False).reset_index(drop=True)\n",
    "\n",
    "        # Make copy of df, remove 2nd and 3rd log keeping 1st and 4th log of one eq entry.\n",
    "        run_df = temp_df.copy()\n",
    "        while x < len(temp_df.index):\n",
    "            run_df=run_df.drop(x)\n",
    "            x+=1\n",
    "            run_df=run_df.drop(x)\n",
    "            x+=3\n",
    "\n",
    "        # Reset index \n",
    "        run_df = run_df.reset_index(drop=True) \n",
    "\n",
    "        # get difference of weather change from day of eq and few days before\n",
    "        i = 0\n",
    "        new_col = []\n",
    "        # Icon list will tell style which icon to display\n",
    "        icon_list = []\n",
    "        while i < len(run_df.index):\n",
    "        #     for data in run_df.index:\n",
    "            first = run_df.iloc[i,2]\n",
    "            second = run_df.iloc[i+1, 2]\n",
    "            difference = first - second\n",
    "            new_col.append(difference)\n",
    "            new_col.append(difference)\n",
    "            i+=2    \n",
    "        # Add new list to df as a new column  \n",
    "        run_df['difference'] = new_col     \n",
    "        for x in run_df['difference']:\n",
    "            if x > 0:\n",
    "                icon = \"up\"\n",
    "                icon_list.append(icon)\n",
    "            elif x == 0:\n",
    "                icon = \"nochange\"\n",
    "                icon_list.append(icon)\n",
    "            else:\n",
    "                icon = \"down\"\n",
    "                icon_list.append(icon)\n",
    "\n",
    "        # Add new list to df as a new column\n",
    "        run_df['icon'] = icon_list    \n",
    "        # select only the columns we need\n",
    "        run_df = run_df[['date','magnitude','lat','difference','icon']]\n",
    "\n",
    "        # # Turn df into list of tuples\n",
    "        records = run_df.to_records(index=False)\n",
    "        analysis_chart = list(records)\n",
    "\n",
    "        # Create list of tuple\n",
    "        analysis_list = []\n",
    "        for data in analysis_chart:\n",
    "            container2 = {\n",
    "                \"date\": data.date, \n",
    "                \"magnitude\": data.magnitude, \n",
    "                \"lat\": data.lat, \n",
    "                \"difference\": data.difference, \n",
    "                \"icon\": data.icon,\n",
    "                }\n",
    "            analysis_list.append(container2)\n",
    "        return analysis_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-17T20:51:48.428581Z",
     "start_time": "2020-08-17T20:51:48.424591Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-17T22:02:33.512474Z",
     "start_time": "2020-08-17T22:02:33.500521Z"
    }
   },
   "outputs": [],
   "source": [
    "#################################################################\n",
    "## Facts \n",
    "##################################################################\n",
    "\n",
    "def aboveSixQuakeCall():\n",
    "    # Sets an object to utilize the default declarative base in SQL Alchemy\n",
    "    Base = declarative_base()\n",
    "    ## Class base template to upload to sqlite\n",
    "    class WeatherSeries(Base):\n",
    "        __tablename__ = 'weatherSeries'\n",
    "\n",
    "        id = Column(Integer, primary_key=True)\n",
    "        city = Column(String(50))\n",
    "        country = Column(String(200))\n",
    "        region = Column(String(80))\n",
    "        avgtemp = Column(Float)\n",
    "        date = Column(String(12))\n",
    "        date_epoch = Column(Float)\n",
    "        maxtemp = Column(Float)\n",
    "        mintemp = Column(Float)\n",
    "        sunhour = Column(Float)\n",
    "        totalsnow = Column(Float)\n",
    "        uv_index = Column(Float)\n",
    "        magnitude = Column(Float)\n",
    "        place = Column(String(80))\n",
    "        lat = Column(String(12))\n",
    "        long = Column(String(12))\n",
    "\n",
    "    # Create Database Connection\n",
    "    # ----------------------------------\n",
    "    # Creates a connection to our DB\n",
    "    # Engine opens the door. Conn is the walk through sign\n",
    "    engine = create_engine(\"sqlite:///earthquake_weather.sqlite\")\n",
    "    conn = engine.connect()\n",
    "    # Create a \"Metadata\" Layer That Abstracts our SQL Database\n",
    "    # ----------------------------------\n",
    "    # Create (if not already in existence) the tables associated with our classes.\n",
    "    Base.metadata.create_all(engine)\n",
    "    # Create a Session Object to Connect to DB\n",
    "    # ----------------------------------\n",
    "    session = Session(bind=engine)\n",
    "\n",
    "    def aboveSixQuake():\n",
    "        Base = automap_base()\n",
    "        Base.prepare(engine, reflect=True)\n",
    "        # Check db table names\n",
    "        # Base.classes.keys()\n",
    "        weather_table = Base.classes.weatherSeries\n",
    "        \n",
    "#         weather_container = session.query(weather_table).order_by(desc(weather_table.magnitude)).limit(1).all()\n",
    "        \n",
    "        weather_container = session.query(weather_table).filter(weather_table.magnitude > 6).all()\n",
    "        weather_facts = []\n",
    "        magnitude_list = []\n",
    "        count = 0\n",
    "        for data in weather_container:\n",
    "            count += 1\n",
    "            \n",
    "            # make a list of magnitudes recorded greater than 6 and get avg temp\n",
    "            magnitude_list.append(data.avgtemp)\n",
    "            magnitude = data.magnitude\n",
    "            magnitude_keep = 6\n",
    "            # Get highest recorded earthquake\n",
    "            if data.magnitude > magnitude_keep:\n",
    "                magnitude_keep = data.magnitude\n",
    "                location = data.country\n",
    "                city = data.city\n",
    "                temp_low = data.mintemp\n",
    "                temp_high = data.maxtemp\n",
    "                avg_temp_at_time = data.avgtemp\n",
    "                date = data.date\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "\n",
    "\n",
    "        def spellDate(datestring):\n",
    "            date_time_obj = datetime.datetime.strptime(datestring, '%Y-%m-%d')\n",
    "            month_name = date_time_obj.strftime(\"%B\")\n",
    "            day = date_time_obj.strftime(\"%d\")\n",
    "            year = date_time_obj.strftime(\"%Y\")\n",
    "\n",
    "            month_day = month_name + \" \" + day\n",
    "            month_day_year = month_name + \" \" + day + \", \" + year\n",
    "\n",
    "            date = {\n",
    "                \"month_day\": month_day,\n",
    "                \"month_day_year\": month_day_year,\n",
    "            }\n",
    "            return date  \n",
    "\n",
    "  \n",
    "        # Get avgtemp from list        \n",
    "        def Average(lst): \n",
    "            return sum(lst) / len(lst) \n",
    "        quake_avg = Average(magnitude_list)\n",
    "\n",
    "\n",
    "        spell_dates = spellDate(date)\n",
    "        \n",
    "        container = {\n",
    "            \"count\": count, \n",
    "            \"avgtemp\": quake_avg,\n",
    "            \"highest_magnitude\": magnitude_keep, \n",
    "            \"highest_city\": city,\n",
    "            \"highest_location\": location,\n",
    "            \"temp_low\": temp_low,\n",
    "            \"temp_high\": temp_high,\n",
    "            \"avg_temp_at_time\": avg_temp_at_time,\n",
    "            \"date\": spell_dates,\n",
    "            \n",
    "        }\n",
    "        weather_facts.append(container)\n",
    "        return weather_facts\n",
    "\n",
    "    weather_facts = aboveSixQuake()\n",
    "\n",
    "    # Return results\n",
    "    return weather_facts\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-16T10:03:27.310439Z",
     "start_time": "2020-08-16T10:03:27.304455Z"
    }
   },
   "outputs": [],
   "source": [
    "def latestQuakes():\n",
    "    Base = automap_base()\n",
    "    Base.prepare(engine, reflect=True)\n",
    "\n",
    "    weather_table = Base.classes.weatherSeries\n",
    "    weather_container = session.query(weather_table).order_by(desc(weather_table.date)).limit(5).all()\n",
    "\n",
    "    weather_latest5 = []\n",
    "    for data in weather_container:\n",
    "        container = {\n",
    "            \"date\": data.date, \n",
    "            \"city\": data.city, \n",
    "            \"country\": data.country, \n",
    "            \"region\": data.region, \n",
    "            \"place\": data.place,\n",
    "            \"mintemp\": data.mintemp, \n",
    "            \"maxtemp\": data.maxtemp, \n",
    "            \"avgtemp\": data.avgtemp,\n",
    "            \"magnitude\": data.magnitude, \n",
    "            }\n",
    "        weather_latest5.append(container)\n",
    "    return weather_latest5\n",
    "    #     print(container)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-16T09:59:03.333466Z",
     "start_time": "2020-08-16T09:59:03.322493Z"
    }
   },
   "outputs": [],
   "source": [
    "last_five_quakes_df = pd.DataFrame(last_five_quakes)\n",
    "last_five_quakes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-15T03:06:40.407559Z",
     "start_time": "2020-08-15T03:06:40.402537Z"
    }
   },
   "outputs": [],
   "source": [
    "# def weatherTimeSeries(query_call):\n",
    "#     Base = automap_base()\n",
    "#     Base.prepare(engine, reflect=True)\n",
    "#     # Check db table names\n",
    "#     # Base.classes.keys()\n",
    "#     weather_table = Base.classes.weatherSeries\n",
    "#     weather_container = session.query(weather_table).filter(weather_table.lat == query_call).all()\n",
    "#     weather_data = []\n",
    "#     for data in weather_container:\n",
    "#         container = {\n",
    "#             \"city\": data.city, \n",
    "#             \"country\": data.country, \n",
    "#             \"region\": data.region, \n",
    "#             \"avgtemp\": data.avgtemp, \n",
    "#             \"date\": data.date, \n",
    "#             \"date_epoch\": data.date_epoch, \n",
    "#             \"maxtemp\": data.maxtemp, \n",
    "#             \"mintemp\": data.mintemp, \n",
    "#             \"sunhour\": data.sunhour, \n",
    "#             \"totalsnow\": data.totalsnow, \n",
    "#             \"uv_index\": data.uv_index, \n",
    "#             \"magnitude\": data.magnitude, \n",
    "#             \"place\": data.place, \n",
    "#             \"lat\": data.lat, \n",
    "#             \"long\": data.long\n",
    "#         }\n",
    "#         weather_data.append(container)\n",
    "#     return weather_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# latitude = '53.42'\n",
    "# query_from_db_to_web = weatherTimeSeries(latitude)\n",
    "# query_from_db_to_web"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-16T21:37:15.256021Z",
     "start_time": "2020-08-16T21:37:15.251005Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "dt3 = datetime.fromtimestamp(1597074974330 / 1000)\n",
    "dt3.strftime(\"%B\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-16T21:38:42.330991Z",
     "start_time": "2020-08-16T21:38:42.324983Z"
    }
   },
   "outputs": [],
   "source": [
    "dt3 = datetime.fromtimestamp(1597074974330 / 1000)\n",
    "month_name = dt3.strftime(\"%B\")\n",
    "day = dt3.strftime(\"%d\")\n",
    "year = dt3.strftime(\"%Y\")\n",
    "\n",
    "month_day = month_name + \" \" + day\n",
    "month_day_year = month_name + \" \" + day + \", \" + year\n",
    "\n",
    "date = {\n",
    "    \"month_day\": month_day,\n",
    "    \"month_day_year\": month_day_year,\n",
    "}\n",
    "date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-16T21:39:45.230496Z",
     "start_time": "2020-08-16T21:39:45.224511Z"
    }
   },
   "outputs": [],
   "source": [
    "def spellDateUnix(datestring):\n",
    "    dt3 = datetime.fromtimestamp(datestring / 1000)\n",
    "    month_name = dt3.strftime(\"%B\")\n",
    "    day = dt3.strftime(\"%d\")\n",
    "    year = dt3.strftime(\"%Y\")\n",
    "\n",
    "    month_day = month_name + \" \" + day\n",
    "    month_day_year = month_name + \" \" + day + \", \" + year\n",
    "\n",
    "    date = {\n",
    "        \"month_day\": month_day,\n",
    "        \"month_day_year\": month_day_year,\n",
    "    }\n",
    "\n",
    "    return date\n",
    "spellDateUnix(1597074974330)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-16T03:18:25.068042Z",
     "start_time": "2020-08-16T03:18:25.059038Z"
    }
   },
   "outputs": [],
   "source": [
    "def spellDate(datestring):\n",
    "    date_time_obj = datetime.datetime.strptime(datestring, '%Y-%m-%d')\n",
    "    month_name = date_time_obj.strftime(\"%B\")\n",
    "    day = date_time_obj.strftime(\"%d\")\n",
    "    year = date_time_obj.strftime(\"%Y\")\n",
    "\n",
    "    month_day = month_name + \" \" + day\n",
    "    month_day_year = month_name + \" \" + day + \", \" + year\n",
    "\n",
    "    date = {\n",
    "        \"month_day\": month_day,\n",
    "        \"month_day_year\": month_day_year,\n",
    "    }\n",
    "    return date\n",
    "\n",
    "\n",
    "def aboveSixQuake():\n",
    "    Base = automap_base()\n",
    "    Base.prepare(engine, reflect=True)\n",
    "    # Check db table names\n",
    "    # Base.classes.keys()\n",
    "    weather_table = Base.classes.weatherSeries\n",
    "    weather_container = session.query(weather_table).filter(weather_table.magnitude > 6).all()\n",
    "    weather_facts = []\n",
    "    magnitude_list = []\n",
    "    count = 0\n",
    "    for data in weather_container:\n",
    "        count += 1\n",
    "        \n",
    "        # make a list of magnitudes recorded greater than 6 and get avg temp\n",
    "        magnitude_list.append(data.avgtemp)\n",
    "        magnitude = data.magnitude\n",
    "        magnitude_keep = 6\n",
    "        # Get highest recorded earthquake\n",
    "        if data.magnitude > magnitude_keep:\n",
    "            magnitude_keep = data.magnitude\n",
    "            location = data.country\n",
    "            city = data.city\n",
    "            temp_low = data.mintemp\n",
    "            temp_high = data.maxtemp\n",
    "            avg_temp_at_time = data.avgtemp\n",
    "            date = data.date\n",
    "        else:\n",
    "            continue\n",
    "            \n",
    "    # Get avgtemp from list        \n",
    "    def Average(lst): \n",
    "        return sum(lst) / len(lst) \n",
    "    quake_avg = Average(magnitude_list)\n",
    "\n",
    "\n",
    "    spell_dates = spellDate(date)\n",
    "    \n",
    "    container = {\n",
    "        \"count\": count, \n",
    "        \"avgtemp\": quake_avg,\n",
    "        \"highest_magnitude\": magnitude_keep, \n",
    "        \"highest_city\": city,\n",
    "        \"highest_location\": location,\n",
    "        \"temp_low\": temp_low,\n",
    "        \"temp_high\": temp_high,\n",
    "        \"avg_temp_at_time\": avg_temp_at_time,\n",
    "        \"date\": spell_dates,\n",
    "         \n",
    "    }\n",
    "    weather_facts.append(container)\n",
    "    return weather_facts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-16T03:18:25.305858Z",
     "start_time": "2020-08-16T03:18:25.282918Z"
    }
   },
   "outputs": [],
   "source": [
    "query_from_db_to_web = aboveSixQuake()\n",
    "query_from_db_to_web"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Convert Date to \"August 10, 2020\" and \"August 10\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-16T01:14:15.836525Z",
     "start_time": "2020-08-16T01:14:15.832508Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-16T03:18:31.806564Z",
     "start_time": "2020-08-16T03:18:31.803571Z"
    }
   },
   "outputs": [],
   "source": [
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-16T01:27:05.971764Z",
     "start_time": "2020-08-16T01:27:05.967774Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import datetime\n",
    "\n",
    "def spellDate(datestring):\n",
    "    \n",
    "    date_time_obj = datetime.datetime.strptime(datestring, '%Y-%m-%d')\n",
    "    month_name = date_time_obj.strftime(\"%B\")\n",
    "    day = date_time_obj.strftime(\"%d\")\n",
    "    year = date_time_obj.strftime(\"%Y\")\n",
    "\n",
    "    month_day = month_name + \" \" + day\n",
    "    month_day_year = month_name + \" \" + day + \", \" + year\n",
    "    \n",
    "    date = {\n",
    "        \"month_day\": month_day,\n",
    "        \"month_day_year\": month_day_year,\n",
    "    }\n",
    "    return date\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# latlong_container = session.query(latlong_table).filter(latlong_table.lat == '').all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-13T03:18:50.959907Z",
     "start_time": "2020-08-13T03:18:50.956886Z"
    }
   },
   "outputs": [],
   "source": [
    "# for data in latlong_table:\n",
    "#     print(f\"Date: {data.lat}, Temp: {data.long}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-13T03:17:44.639252Z",
     "start_time": "2020-08-13T03:17:44.635284Z"
    }
   },
   "outputs": [],
   "source": [
    "# Join two tables in the db\n",
    "# def join_example():\n",
    "#     records = session.query(WeatherSeries).\\\n",
    "#         join(LatLong, LatLong.id == WeatherSeries.id).all()\n",
    "# #     print(records)\n",
    "#     for record in records:\n",
    "#         recordObject = {\n",
    "#             'city': record.city,\n",
    "#             'country': record.country,\n",
    "#             'date': record.date,\n",
    "#             'maxtemp': record.maxtemp,\n",
    "#             'latlong_rel': record.latlong_rel\n",
    "#         }\n",
    "#         print(recordObject)\n",
    "# join_example()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-13T03:10:23.766957Z",
     "start_time": "2020-08-13T03:10:23.751969Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create DataFrame from sql table Weather\n",
    "# weather_data_df = pd.read_sql(\"SELECT * FROM LatLong\", conn)\n",
    "# weather_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### \n",
    "## KEEP !!\n",
    "## DO NOT DELETE ALL THIS\n",
    "###\n",
    "\n",
    "# Create a Specific Instance of the \"weather_data\" and \"earthquake_data\" classes\n",
    "# ----------------------------------\n",
    "# Data needs to pass through this. A for loop while need to be created to consistantly send multiple files\n",
    "# weather_data = WeatherSeries(\n",
    "#     lat = '',\n",
    "#     lon = '',\n",
    "#     date = '',\n",
    "#     city = '',\n",
    "#     country = '',\n",
    "#     region = '',\n",
    "#     avgtemp = '',\n",
    "#     date_epoch = '',\n",
    "#     maxtemp = '',\n",
    "#     mintemp = '',\n",
    "#     sunhour = '',\n",
    "#     totalsnow = '',\n",
    "#     uv_index = '',\n",
    "#     )\n",
    "\n",
    "# earthquake_data = Earthquake(\n",
    "#     lat = '',\n",
    "#     lon = '',\n",
    "#     date = '',\n",
    "#     mag = '',\n",
    "#     location = ''\n",
    "#     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-12T10:27:56.043030Z",
     "start_time": "2020-08-12T10:27:56.040038Z"
    }
   },
   "outputs": [],
   "source": [
    "# def checkEqual3(lst):\n",
    "#     return lst[1:] == lst[:-1]\n",
    "\n",
    "# def checkRowValueDups(data):\n",
    "#     dictOfKeys = data.keys()\n",
    "#     for column in data:\n",
    "#         column_values = data[column].to_list()\n",
    "#         result = checkEqual3(column_values)\n",
    "# #         print('passed.')\n",
    "#     if result == True:\n",
    "#         all_logs_df = all_logs.iloc[0:1, 0:]\n",
    "#     else:\n",
    "#         print(\"Couldnt complete cleaning. Different value found in column where only duplicates live. Check function checkRowValueDups() for information\")\n",
    "#     return all_logs_df\n",
    "\n",
    "# all_logs_df = checkRowValueDups(all_logs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-12T10:27:58.503194Z",
     "start_time": "2020-08-12T10:27:58.500244Z"
    }
   },
   "outputs": [],
   "source": [
    "# all_logs_df['2020-08-03'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stuff = (list(all_logs.itertuples(index=False, name=None)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.7 64-bit ('usc_bootcamp': conda)",
   "language": "python",
   "name": "python37764bituscbootcampconda3361b9ec87e5404d80e03b8fe2fcfaaf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
